DATA PREP
Separating training data into 2 sets to get a sense of accuracy
Uses caret package
20% testing.csv
80% training.csv

SUBMISSION 1
Prediction based on gender
Working through the python tutorial at kaggle, converting to R
http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-python
kaggle 0.76555

SUBMISSION 2
Random Forest
Working through the getting started with random forests at kaggle, converting to R
http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-random-forests
kaggle 0.77512

SUBMISSION 3
Generalized Linear Model 
Uses glm to predict survived using same clean data from sub2
kaggle 0.76555

SUBMISSION 4
Random Forest
Re-cleaning data, retaining Cabin and Ticket data and predicting fills instead of using means
accuracy on cleaned train data (all): ~94%
kaggle 0.727272

SUBMISSION 5
Logistic regression
Porting Octave code from Machine Learning class to R
Going to try with the clean data from sub4
This isn't going to do well but I'll submit it anyway, just to see
accuracy on sub4 train data(all):81.25
kaggle: 0.76077

SUBMISSION 6
Survivor Table for gender, class and fare
Implementing the survivor table described in the kaggle tutorials, writing it in R with no changes
Using the clean data from sub4
accuracy on sub4 train data(all):78.68
kaggle:0.75598

Ideas:
X Clean data using prediction instead of means
Include ticket and cabin data
X Logistic regression using model taught in Machine Learning
Neural Network
SVM
Spend more time on visualization





